{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514173a-5735-4dc3-8076-96dfc6f9f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import itertools\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "from data_utils import (\n",
    "    WBCdataset\n",
    ")\n",
    "from models import (\n",
    "    ViT\n",
    ")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def get_transform(is_train):\n",
    "    data_transforms = []\n",
    "    data_transforms.append(transforms.Resize((512, 512)))\n",
    "    if is_train:\n",
    "        data_transforms.append(transforms.RandomHorizontalFlip())\n",
    "    data_transforms.append(transforms.ToTensor())\n",
    "    return transforms.Compose(data_transforms)\n",
    "\n",
    "def run(device, hps):\n",
    "    train_data = WBCdataset(hps.WBCdata.training_files, hps.WBCdata.label_dict, transform=get_transform(True))\n",
    "    valid_data = WBCdataset(hps.WBCdata.validation_files, hps.WBCdata.label_dict, transform=get_transform(False))\n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_data, batch_size=hps.train.batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(dataset = valid_data, batch_size=hps.train.batch_size, shuffle=True)\n",
    "    \n",
    "    model = ViT(\n",
    "        image_size = hps.WBCdata.image_size,\n",
    "        patch_size = hps.WBCdata.patch_size,\n",
    "        num_classes = hps.WBCdata.num_classes,\n",
    "        **hps.ViTmodel\n",
    "    ).to(device)\n",
    "    \n",
    "    # loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hps.train.learning_rate)\n",
    "    # scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=hps.train.lr_decay)\n",
    "    \n",
    "    for epoch in range(hps.train.epochs):\n",
    "        train_and_evaluate(device, epoch, model, criterion, optimizer, [train_loader, valid_loader])\n",
    "\n",
    "def train_and_evaluate(device, epoch, model, criterion, optimizer, loaders):\n",
    "    train_loader, valid_loader = loaders\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in valid_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(valid_loader)\n",
    "            epoch_val_loss += val_loss / len(valid_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e769a1-dfe0-4704-837f-541f0bd3ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = utils.get_hparams_from_file('./configs/base.json')\n",
    "seed_everything(hps.train.seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "run(device, hps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
